# ============================================================
# [FINAL v2] GitHub Actionsìš© TIL ë´‡ (ì¿ í‚¤ ë¡œê·¸ì¸ í”„ë¦¬íŒ¨ìŠ¤ íƒ‘ì¬)
# ============================================================

# ğŸ‘‡ [ìˆ˜ì§‘ ë‚ ì§œ ì„¤ì •]
# Noneìœ¼ë¡œ ë‘ë©´ ì‹œìŠ¤í…œì´ 'ê°€ì¥ ìµœê·¼ ì˜ì—…ì¼'ì„ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤.
# íŠ¹ì • ë‚ ì§œë¥¼ ìˆ˜ì§‘í•˜ë ¤ë©´ "2025-11-27" ì²˜ëŸ¼ ë¬¸ìì—´ë¡œ ì ìœ¼ì„¸ìš”.
TARGET_DATE_OVERRIDE = None 

import subprocess
import time
import os
import sys
import socket
import json # json ì²˜ë¦¬ìš© ëª¨ë“ˆ ì¶”ê°€
import pandas as pd
from datetime import datetime, timedelta
from dotenv import load_dotenv
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys

load_dotenv() 

# ============================================================
# Config
# ============================================================

class Config:
    BACKOFFICE_URL = os.environ.get("BACKOFFICE_URL")
    if not BACKOFFICE_URL:
        raise ValueError("âŒ 'BACKOFFICE_URL' í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

    COURSE_NAME = "QA 4ê¸°"
    COURSE_KEYWORDS = ["KDT", "QA", "4"]
    BATCH_NAME = "4íšŒì°¨"
    CATEGORY = "QA/QC"
    
    CHROME_DEBUG_PORT = 9222
    if sys.platform == "darwin":
        CHROME_APP_PATH = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
    else:
        CHROME_APP_PATH = "/usr/bin/google-chrome"
        
    USER_DATA_DIR = "~/apm_profile"
    WAIT_TIMEOUT = 20           
    CHROME_LAUNCH_WAIT = 4      
    MENU_CLICK_WAIT = 1         
    PAGE_LOAD_WAIT = 2          
    SEARCH_WAIT = 3             
    DATA_COLLECTION_WAIT = 0.5  
    PAGE_NAVIGATION_WAIT = 2
    MODAL_WAIT = 0.8 

    HOLIDAYS_KR = {
        "2025-01-01": "ì‹ ì •", "2025-01-27": "ì„¤ë‚  ì—°íœ´", "2025-01-28": "ì„¤ë‚ ", 
        "2025-01-29": "ì„¤ë‚  ì—°íœ´", "2025-01-30": "ì„¤ë‚  ëŒ€ì²´ê³µíœ´ì¼",
        "2025-03-01": "ì‚¼ì¼ì ˆ", "2025-03-03": "ì‚¼ì¼ì ˆ ëŒ€ì²´ê³µíœ´ì¼", 
        "2025-05-05": "ì–´ë¦°ì´ë‚ ", "2025-05-06": "ë¶€ì²˜ë‹˜ì˜¤ì‹ ë‚  ëŒ€ì²´ê³µíœ´ì¼",
        "2025-06-03": "ëŒ€í†µë ¹ì„ ê±°(ì„ì‹œ)", "2025-06-06": "í˜„ì¶©ì¼", 
        "2025-08-15": "ê´‘ë³µì ˆ", "2025-10-03": "ê°œì²œì ˆ",
        "2025-10-05": "ì¶”ì„ ì—°íœ´", "2025-10-06": "ì¶”ì„", "2025-10-07": "ì¶”ì„ ì—°íœ´", 
        "2025-10-08": "ì¶”ì„ ëŒ€ì²´ê³µíœ´ì¼", "2025-10-09": "í•œê¸€ë‚ ", "2025-12-25": "í¬ë¦¬ìŠ¤ë§ˆìŠ¤"
    }

# ============================================================
# Helper Classes
# ============================================================

class DateCalculator:
    @staticmethod
    def get_target_date(config: Config) -> str:
        cursor = datetime.now().date()
        cursor -= timedelta(days=1)
        while True:
            cursor_str = cursor.strftime("%Y-%m-%d")
            if cursor.weekday() >= 5:
                cursor -= timedelta(days=1)
                continue
            if cursor_str in config.HOLIDAYS_KR:
                print(f"ğŸ–ï¸ ê³µíœ´ì¼ ìŠ¤í‚µ: {cursor_str}")
                cursor -= timedelta(days=1)
                continue
            return cursor_str

# [ìˆ˜ì •ë³¸] ChromeManager (ì„œë²„ì¸ ì²™ ì•ˆ í•˜ê³  ë§¥ë¶ì¸ ì²™ ìœ„ì¥í•˜ê¸°)

class ChromeManager:
    @staticmethod
    def launch_chrome(config: Config):
        options = webdriver.ChromeOptions()
        
        # 1. í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ (ì„œë²„ë‹ˆê¹Œ í•„ìˆ˜)
        options.add_argument("--headless=new") 
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--window-size=1920,1080")
        
        # ğŸ‘‡ [í•µì‹¬] ê°€ë©´ ì“°ê¸° (User-Agent ë³€ì¡°)
        # "ë‚˜ëŠ” ë¦¬ëˆ…ìŠ¤ ì„œë²„ê°€ ì•„ë‹ˆë¼, ìµœì‹  ë§¥ë¶ í¬ë¡¬ì´ë‹¤!" ë¼ê³  ì†ì„
        user_agent = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        options.add_argument(f"user-agent={user_agent}")
        
        # ë´‡ íƒì§€ ë°©ì§€ ì˜µì…˜ ì¶”ê°€
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)

        print("ğŸ•µï¸â€â™‚ï¸ í¬ë¡¬ ë“œë¼ì´ë²„(Headless + ìœ„ì¥ ëª¨ë“œ) ì´ˆê¸°í™” ì¤‘...")
        
        try:
            driver = webdriver.Chrome(
                service=Service(ChromeDriverManager().install()), 
                options=options
            )
            
            # [ì¤‘ìš”] navigator.webdriver ì†ì„±ì„ ìˆ¨ê²¨ì„œ ì™„ë²½í•˜ê²Œ ì‚¬ëŒì¸ ì²™ í•¨
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            return driver
        except Exception as e:
            print(f"âŒ í¬ë¡¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            sys.exit(1)

# ============================================================
# Crawler (Updated with Cookie Logic)
# ============================================================

class BackOfficeCrawler:
    def __init__(self, driver, config: Config):
        self.driver = driver
        self.config = config
        self.wait = WebDriverWait(driver, config.WAIT_TIMEOUT)
    
    def force_click(self, element):
        try: element.click()
        except: self.driver.execute_script("arguments[0].click();", element)

    def navigate_and_search(self):
        print("\nğŸ”— ë°±ì˜¤í”¼ìŠ¤ ì§„ì… ì¤‘...")
        
        # 1. ì‚¬ì´íŠ¸ ì ‘ì† (ë¡œê·¸ì¸ ì•ˆ ëœ ìƒíƒœ)
        self.driver.get(self.config.BACKOFFICE_URL)
        
        # 2. [í•µì‹¬] ì¿ í‚¤ ì£¼ì… (ë¡œê·¸ì¸ ìš°íšŒ)
        cookies_json = os.environ.get("BACKOFFICE_COOKIES")
        
        if cookies_json:
            print("ğŸª [ì„œë²„ ëª¨ë“œ] ì €ì¥ëœ ì¿ í‚¤ë¥¼ ì£¼ì…í•˜ì—¬ ë¡œê·¸ì¸ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            try:
                cookies = json.loads(cookies_json)
                for cookie in cookies:
                    # Selenium í˜¸í™˜ì„±ì„ ìœ„í•´ ë¶ˆí•„ìš”í•œ í‚¤ ì‚­ì œ
                    if 'expiry' in cookie:
                        del cookie['expiry']
                    if 'sameSite' in cookie:
                        del cookie['sameSite'] # ê°€ë” ì¶©ëŒë‚¨
                        
                    try:
                        self.driver.add_cookie(cookie)
                    except Exception as e:
                        # ë„ë©”ì¸ ë¶ˆì¼ì¹˜ ë“± ì‚¬ì†Œí•œ ì¿ í‚¤ ì—ëŸ¬ëŠ” ë¬´ì‹œ
                        pass
                
                print("ğŸ”„ ì¿ í‚¤ ì£¼ì… ì™„ë£Œ. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.")
                self.driver.refresh()
                time.sleep(3) # ìƒˆë¡œê³ ì¹¨ í›„ ë¡œê·¸ì¸ ì ìš© ëŒ€ê¸°
                
            except Exception as e:
                print(f"âš ï¸ ì¿ í‚¤ ì ìš© ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
        else:
            print("â„¹ï¸ [ë¡œì»¬ ëª¨ë“œ] ê¸°ì¡´ ë¸Œë¼ìš°ì € ì„¸ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # 3. ë©”ë‰´ ì´ë™ (ê¸°ì¡´ ë¡œì§)
        print("ğŸ‘‰ ë©”ë‰´ ì´ë™ ì‹œë„...")
        try:
            time.sleep(2)
            menu_xpath = "//span[contains(text(), 'TIL ì œì¶œ í˜„í™© ê´€ë¦¬')]"
            menu = self.driver.find_elements(By.XPATH, menu_xpath)
            
            if not menu or not menu[0].is_displayed():
                op_menu = self.driver.find_element(By.XPATH, "//*[contains(text(), 'ë‚´ë°°ìº  ìš´ì˜')]")
                self.force_click(op_menu)
                time.sleep(1)
            
            real_menu = self.wait.until(EC.element_to_be_clickable((By.XPATH, menu_xpath)))
            self.force_click(real_menu)
            print("âœ… ë©”ë‰´ ì§„ì… ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ ë©”ë‰´ ì´ë™ ì‹¤íŒ¨ (ë¡œê·¸ì¸ ì‹¤íŒ¨ ê°€ëŠ¥ì„±): {e}")
            # ìŠ¤í¬ë¦°ìƒ· ì°ì–´ì„œ ë””ë²„ê¹… ê°€ëŠ¥í•˜ê²Œ (ì„ íƒ)
            # self.driver.save_screenshot("login_failed.png")
        
        time.sleep(2)
        
        try:
            search_btn = self.wait.until(EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'ì¡°íšŒí•˜ê¸°')]")))
            self.force_click(search_btn)
            time.sleep(3)
        except: pass

    def collect_data(self, target_date: str) -> list:
        print(f"\nğŸ¢ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (íƒ€ê²Ÿ ë‚ ì§œ: {target_date})")
        total_data = []
        current_page = 1
        MAX_PAGES = 50
        
        while current_page <= MAX_PAGES:
            print(f"\nğŸ“„ [Page {current_page}] ìŠ¤ìº” ì¤‘...", end="")
            time.sleep(self.config.DATA_COLLECTION_WAIT)
            
            rows = self.driver.find_elements(By.CSS_SELECTOR, "tr.ant-table-row")
            if not rows:
                print("\n   âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë¡œê·¸ì¸ì´ í’€ë ¸ê±°ë‚˜ ë°ì´í„° ë)")
                break
            
            row_count = len(rows)
            print(f" -> {row_count}ëª… ë°œê²¬")
            
            for i in range(row_count):
                try:
                    current_row = self.driver.find_elements(By.CSS_SELECTOR, "tr.ant-table-row")[i]
                    name = current_row.find_elements(By.TAG_NAME, "td")[0].text.strip()
                    print(f"   ğŸ” ({i+1}/{row_count}) {name}ë‹˜ í™•ì¸ ì¤‘...", end="\r")
                    
                    btn = current_row.find_element(By.XPATH, ".//button[contains(., 'ì œì¶œ ë‚´ì—­ ë³´ê¸°') or span[contains(., 'ì œì¶œ ë‚´ì—­ ë³´ê¸°')]]")
                    self.force_click(btn)
                    
                    modal = self.wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, ".ant-modal-content")))
                    time.sleep(self.config.MODAL_WAIT)
                    
                    status = 0
                    found_date = False
                    
                    modal_rows = modal.find_elements(By.CSS_SELECTOR, "tr.ant-table-row")
                    for m_row in modal_rows:
                        cols = m_row.find_elements(By.TAG_NAME, "td")
                        if not cols: continue
                        if cols[0].text.strip() == target_date:
                            status_txt = cols[1].text.strip()
                            if "ë¯¸ì œì¶œ" in status_txt: status = 0
                            elif "ì œì¶œ" in status_txt or "ì™„ë£Œ" in status_txt: status = 1
                            else: status = 0
                            found_date = True
                            break
                    
                    close = modal.find_element(By.XPATH, ".//button[contains(., 'OK')]")
                    self.force_click(close)
                    self.wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, ".ant-modal-content")))
                    time.sleep(0.3)
                    
                    total_data.append({"ì´ë¦„": name, "ë‚ ì§œ": target_date, "ì œì¶œì—¬ë¶€": status})
                except Exception as e:
                    print(f"\n   âŒ ì—ëŸ¬: {e}")
                    try: webdriver.ActionChains(self.driver).send_keys(Keys.ESCAPE).perform(); time.sleep(1)
                    except: pass
                    continue
            
            try:
                next_btns = self.driver.find_elements(By.CSS_SELECTOR, "li.ant-pagination-next")
                if next_btns and "ant-pagination-disabled" not in next_btns[0].get_attribute("class"):
                     self.force_click(next_btns[0])
                     current_page += 1
                     time.sleep(2)
                else: break
            except: break
            
        return total_data

def extract_til_data(manual_date: str = None) -> pd.DataFrame:
    config = Config()
    if manual_date:
        print(f"ğŸ› ï¸ [ìˆ˜ë™ ëª¨ë“œ] '{manual_date}' ìˆ˜ì§‘")
        target_date = manual_date
    else:
        print("ğŸ¤– [ìë™ ëª¨ë“œ] ë‚ ì§œ ê³„ì‚° ì¤‘...")
        target_date = DateCalculator.get_target_date(config)
        
    driver = ChromeManager.launch_chrome(config)
    try:
        crawler = BackOfficeCrawler(driver, config)
        crawler.navigate_and_search()
        data = crawler.collect_data(target_date)
        df = pd.DataFrame(data)
        print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(df)}ê±´.")
        return df
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        return pd.DataFrame()

# ============================================================
# Uploader
# ============================================================

JSON_FILE = "qaqc-pipeline.json" 
TIL_SHEET_URL = os.environ.get("TIL_SHEET_URL")

class GoogleSheetManager:
    def __init__(self):
        if not TIL_SHEET_URL:
            raise ValueError("âŒ 'TIL_SHEET_URL' ì—†ìŒ")
        self.scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        try:
            self.creds = ServiceAccountCredentials.from_json_keyfile_name(JSON_FILE, self.scope)
            self.client = gspread.authorize(self.creds)
            self.sheet = self.client.open_by_url(TIL_SHEET_URL).sheet1
            print("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise e

    def save_data(self, new_df: pd.DataFrame):
        if new_df.empty:
            print("âš ï¸ ë°ì´í„° ì—†ìŒ")
            return
        target_date = new_df.iloc[0]['ë‚ ì§œ']
        print(f"\nğŸ’¾ ì €ì¥ ì‹œì‘ ({target_date})...")
        try:
            existing_data = self.sheet.get_all_records()
            existing_df = pd.DataFrame(existing_data)
        except: existing_df = pd.DataFrame()

        if not existing_df.empty and 'ë‚ ì§œ' in existing_df.columns:
            existing_df['ë‚ ì§œ'] = existing_df['ë‚ ì§œ'].astype(str)
            existing_df = existing_df[existing_df['ë‚ ì§œ'] != str(target_date)]

        final_df = pd.concat([new_df, existing_df], ignore_index=True)
        if 'ë‚ ì§œ' in final_df.columns:
            final_df = final_df.sort_values(by='ë‚ ì§œ', ascending=False)
        final_df = final_df.fillna("") 

        self.sheet.clear()
        data_to_write = [final_df.columns.values.tolist()] + final_df.values.tolist()
        self.sheet.update(data_to_write)
        print(f"âœ… ì €ì¥ ì™„ë£Œ!")

def upload_til_data(df: pd.DataFrame):
    try:
        if df is None or df.empty: return
        manager = GoogleSheetManager()
        manager.save_data(df)
    except Exception as e: print(f"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    df_result = extract_til_data(manual_date=TARGET_DATE_OVERRIDE)
    if not df_result.empty:
        upload_til_data(df_result)